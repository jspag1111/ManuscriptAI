[
    {
        "id": "2bd155b6-f014-4794-9c3e-0323743e7778",
        "title": "d",
        "description": "Draft manuscript",
        "created": 1764561433901,
        "lastModified": 1764563110011,
        "settings": {
            "targetJournal": "",
            "wordCountTarget": 3000,
            "formattingRequirements": "",
            "tone": "Academic and formal"
        },
        "manuscriptMetadata": {
            "authors": [],
            "affiliations": []
        },
        "sections": [
            {
                "id": "dedddfb2-bb16-4417-bc2a-b8ba9931a990",
                "title": "Abstract",
                "content": "\n",
                "userNotes": "Create an abstract on the history of AI in healthcare",
                "versions": [],
                "lastModified": 1764562511636,
                "useReferences": true
            },
            {
                "id": "a803b596-909b-41ce-b90e-1d21fc52c1fc",
                "title": "Introduction",
                "content": "",
                "userNotes": "Introduce the problem and hypothesis...",
                "versions": [],
                "lastModified": 1764561433901,
                "useReferences": true
            },
            {
                "id": "5fa3c3e8-4c57-419c-915c-bab385f1b609",
                "title": "Methods",
                "content": "",
                "userNotes": "Describe the experimental setup...",
                "versions": [],
                "lastModified": 1764561433901,
                "useReferences": true
            },
            {
                "id": "ce4e555a-48a6-4c7f-853a-9e3a4bab2b1b",
                "title": "Results",
                "content": "",
                "userNotes": "Detail the findings...",
                "versions": [],
                "lastModified": 1764561433901,
                "useReferences": true
            },
            {
                "id": "0c17928d-aba4-4666-ad79-130046cf2e25",
                "title": "Discussion",
                "content": "",
                "userNotes": "Interpret the results...",
                "versions": [],
                "lastModified": 1764561433901,
                "useReferences": true
            },
            {
                "id": "e617d49c-0bfc-45f5-a902-b93d3a6f9a79",
                "title": "Conclusion",
                "content": " [[ref:e7982afa-798b-4897-9b15-ce2d0cbdfad7]] [[ref:515c574e-d86a-4d15-ac94-6cdf6b6b3f3d]]",
                "userNotes": "Final thoughts and future directions...",
                "versions": [],
                "lastModified": 1764562353824,
                "useReferences": true
            }
        ],
        "references": [
            {
                "id": "515c574e-d86a-4d15-ac94-6cdf6b6b3f3d",
                "title": "Phase II study of dual epigenetic targeting with chidamide and azacitidine in patients with high-risk acute myeloid leukemia after allo-HSCT.",
                "authors": "Wu Ya-Xue, Wan Chao-Ling, Tan Kai-Wen, Zhang Yang, Zhang Yan-Ming, Zhang Hao, Wu De-Pei, Chen Su-Ning, Wang Ying, Ma Xiao, Dai Hai-Ping, Qian Chong-Sheng, Jiang Shan-Shan, Bao Hai-Yan, Hu Xiao-Hui, Li Zheng, Xue Sheng-Li",
                "year": "2025",
                "publication": "Clinical epigenetics",
                "doi": "10.1186/s13148-025-01987-w",
                "summary": "This phase II study investigated the efficacy and safety of dual epigenetic targeting with chidamide and azacitidine as maintenance therapy to prevent relapse in 48 high-risk acute myeloid leukemia patients post-allogeneic hematopoietic stem cell transplantation. The trial demonstrated promising results, with a low 2-year cumulative incidence of relapse (8.4%) and high relapse-free survival (91.6%), alongside an acceptable toxicity profile, suggesting its potential to improve outcomes in this population.",
                "abstract": "BACKGROUND: Allogeneic hematopoietic stem cell transplantation (allo-HSCT) is potentially the only curative option for high-risk acute myeloid leukemia (AML) patients. However, disease relapse remains the principal cause of treatment failure of these patients, and outcomes of salvage treatments are poor. This research seeks to evaluate the efficacy and safety of a dual epigenetic targeting maintenance therapy with chidamide and azacitidine (AZA) in patients with high-risk AML post-allo-HSCT.\n\nMETHODS: This multicenter, open-label, phase 2 prospective clinical trial (ChiCTR2300067593) recruited and followed up 48 patients diagnosed with high-risk AML post-allo-HSCT from 3 hospitals in China from November 2021 to March 2024. Chidamide (5 mg) was administered orally once daily for 5 days, combined with AZA (75 mg/m2) subcutaneously daily for 5 days, respectively. Treatment started as early as 3 months after transplantation. All patients were in complete remission before each maintenance cycle. A total of 6 cycles was recommended.\n\nRESULTS: The 2-year cumulative incidence of relapse (CIR) was 8.4% (95% CI 4.4-12.4%), 2-year relapse-free survival (RFS) was 91.6% (95% CI 87.6-95.6%), and overall survival (OS) was 97.9% (95% CI 95.8-100%). At the end of the follow-up period, 4 patients relapsed, of which 1 patient died of leukemia recurrence; the other three patients underwent second allo-HSCT and are still alive in remission. The most common adverse events (AEs) were hematological toxicity. No grade > 3 AEs were noted. Graft-versus-host disease (GVHD) occurred in 29.2% (14/48) of patients. Six cases (6/48, 12.5%) were complicated with infection. No treatment-related mortality occurred.\n\nCONCLUSIONS: Dual epigenetic targeting maintenance treatment with CHI-AZA has an acceptable toxicity profile and might potentially be effective to prevent relapse in high-risk AML patients after allo-HSCT.\n\nTRIAL REGISTRATION: ClinicalTrials.gov, ChiCTR2300067593. Registered January 12, 2013.",
                "notes": "Source URL: https://pubmed.ncbi.nlm.nih.gov/41084078/\nPMID: 41084078",
                "articleType": "Clinical Trial, Phase II, Multicenter Study"
            },
            {
                "id": "e7982afa-798b-4897-9b15-ce2d0cbdfad7",
                "title": "Concentration-QTc Analysis of Valemetostat in Patients With Hematologic Malignancies.",
                "authors": "Tachibana Masaya, Poland Bill, Kakurai Yasuyuki, Chen Yang, Li Claire, Lau Yvonne",
                "year": "2025",
                "publication": "Clinical and translational science",
                "doi": "10.1111/cts.70391",
                "summary": "This study assessed the potential for valemetostat, a dual EZH1/2 inhibitor, to cause QT prolongation in patients with hematologic malignancies. A concentration-QTc analysis of 100 patients revealed that all model-predicted changes in the QTc interval, across tested doses, remained below the 10 ms threshold for clinical significance. The analysis therefore supports a lack of a clinically meaningful effect of valemetostat on the QTc interval.",
                "abstract": "This study assessed the potential risk of QT prolongation associated with the dual enhancer of zeste homolog 1/2 inhibitor valemetostat. An evaluation of the relationship between plasma valemetostat concentration and heart-rate-corrected QT (QTc) interval was performed. Time-matched plasma concentration and 12-lead electrocardiogram data were collected from the phase I studies DS3201-A-J101, in patients with relapsed/refractory B-/T-cell non-Hodgkin lymphomas (NCT02732275), and DS3201-A-U102, in patients with relapsed/refractory acute myeloid leukemia and acute lymphoblastic leukemia (NCT03110354). A prespecified linear mixed-effects model was used to assess the effect of valemetostat on change in QTc corrected by the Fridericia method (ΔQTcF). A population-specific method (ΔQTcP) was also used to remove the heart rate interval (RR) dependence. The final dataset contained 769 electrocardiogram measurements from 100 patients. Linear mixed-effects modeling found no significant demographic or clinical covariate effects. The slope versus concentration was significant (95% confidence interval [CI] of the coefficient excluded 0) in the final models for ΔQTcF, but not ΔQTcP, while the relative standard error of the slope was > 50% for both models. Baseline QTc had a negative effect on ΔQTc in all models. At the steady-state geometric mean maximum concentrations in the dose range of 100-700 mg tested in the DS3201-A-J101 and DS3201-A-U102 studies, the 90% CI upper bounds for model-predicted ΔQTcF and ΔQTcP were 1.52-8.38 ms, all of which were below the clinically significant threshold of 10 ms. The analysis supports a lack of a clinically meaningful effect on the QTc interval for valemetostat.",
                "notes": "Source URL: https://pubmed.ncbi.nlm.nih.gov/41258689/\nPMID: 41258689",
                "articleType": "Clinical Trial, Phase I"
            },
            {
                "id": "e11b1ca2-5461-4153-9060-6a2aec24fb95",
                "title": "Concentration–QTc Analysis of Valemetostat in Patients With Hematologic Malignancies",
                "authors": "Tachibana Masaya, Poland Bill, Kakurai Yasuyuki, Chen Yang, Li Claire, Lau Yvonne",
                "year": "2025,11",
                "publication": "Clinical and Translational Science",
                "doi": "10.1111/cts.70391",
                "summary": "",
                "abstract": "ABSTRACT\n                  This study assessed the potential risk of QT prolongation associated with the dual enhancer of zeste homolog 1/2 inhibitor valemetostat. An evaluation of the relationship between plasma valemetostat concentration and heart‐rate‐corrected QT (QTc) interval was performed. Time‐matched plasma concentration and 12‐lead electrocardiogram data were collected from the phase I studies DS3201‐A‐J101, in patients with relapsed/refractory B‐/T‐cell non‐Hodgkin lymphomas (NCT02732275), and DS3201‐A‐U102, in patients with relapsed/refractory acute myeloid leukemia and acute lymphoblastic leukemia (NCT03110354). A prespecified linear mixed‐effects model was used to assess the effect of valemetostat on change in QTc corrected by the Fridericia method (ΔQTcF). A population‐specific method (ΔQTcP) was also used to remove the heart rate interval (RR) dependence. The final dataset contained 769 electrocardiogram measurements from 100 patients. Linear mixed‐effects modeling found no significant demographic or clinical covariate effects. The slope versus concentration was significant (95% confidence interval [CI] of the coefficient excluded 0) in the final models for ΔQTcF, but not ΔQTcP, while the relative standard error of the slope was &gt; 50% for both models. Baseline QTc had a negative effect on ΔQTc in all models. At the steady‐state geometric mean maximum concentrations in the dose range of 100–700 mg tested in the DS3201‐A‐J101 and DS3201‐A‐U102 studies, the 90% CI upper bounds for model‐predicted ΔQTcF and ΔQTcP were 1.52–8.38 ms, all of which were below the clinically significant threshold of 10 ms. The analysis supports a lack of a clinically meaningful effect on the QTc interval for valemetostat.",
                "notes": "",
                "articleType": "journal article"
            }
        ],
        "figures": []
    },
    {
        "id": "0bf72070-cb3e-4261-9e5e-57383311c818",
        "title": "Large Language Modes for Predicting Hospital Discharges",
        "description": "Draft manuscript",
        "created": 1764614580951,
        "lastModified": 1764624676348,
        "settings": {
            "targetJournal": "SGIM",
            "wordCountTarget": 3000,
            "formattingRequirements": "# Main Sections\n1. Background - Describe the context and importance of the study and state the objective(s) and/or hypothesis and/or research question of the study.\n2. Methods - Include a description of the methods used, including study design, setting, population, outcome measures, and analytic procedures.\n3. Results - Describe the results in sufficient detail to support the conclusions. Tabular or graphic results are acceptable. It is not satisfactory to state, \"The results will be discussed,\" or \"Other data will be presented.\" Abstracts that do not provide actual results will not be considered for publication or presentation.\n4. Conclusion - State the implications of the findings for clinical practice, research, education, or policy.\n5. Learning Objectives - (2 required) focused learning objectives, stating what the physician should be able to do after learning from the case presentation. Each learning objective should reflect one of the six ACGME Core Competencies. Objectives are action-oriented and should begin with words such as recognize, diagnose, assess, treat, distinguish, or manage. They should NOT begin with terms like \"know how to\" or \"understand.\"\n\n# Submission Length\n- Limited to 3,000 characters\n\n# Submission and Presentation Tips\nKnow your topic and your intended audience:\n\nWho are the primary attendees you are targeting? - Physicians and hospital administrators interested in learning about the potential of LLMs in predicting discharge\nWhy is this topic important to them? - Important because LLMs offer the ability to predict discharge and also offer reasoning.\nIs it innovative and creative? - Traditional ML algorithms can predict discharge, however it is difficult to understand the reasoning why. LLMs offer reasoning. \nIs the topic timely?\nDoes it help audience members address an urgent need (e.g., accreditation issues)?\nHow much time does your topic require?",
            "tone": "Academic and formal"
        },
        "manuscriptMetadata": {
            "authors": [
                {
                    "id": "eeea8a46-5ca8-4f3a-a4ab-e2bf484136df",
                    "firstName": "Jonathan",
                    "lastName": "Spagnoli, MD",
                    "isCorresponding": true,
                    "affiliationIds": [
                        "d266506a-1322-4076-8755-b32894f0ffc3"
                    ],
                    "email": "jspagnol@med.umich.edu"
                },
                {
                    "id": "15ce110b-7124-41b3-94e2-e2ae49f4f924",
                    "firstName": "Natalie",
                    "lastName": "Guzman, BS",
                    "isCorresponding": false,
                    "affiliationIds": [
                        "2819909b-d808-4ecf-8ff5-df46494cf161"
                    ]
                },
                {
                    "id": "d9dcf432-f62c-44bf-9470-69924ad2e02b",
                    "firstName": "Karan",
                    "lastName": "Desai, BS",
                    "isCorresponding": false,
                    "affiliationIds": [
                        "2819909b-d808-4ecf-8ff5-df46494cf161"
                    ]
                },
                {
                    "id": "c3b00f5b-52de-47e4-93a7-1fec5b293646",
                    "firstName": "Veronica",
                    "lastName": "Gilbert, BS",
                    "isCorresponding": false,
                    "affiliationIds": [
                        "2819909b-d808-4ecf-8ff5-df46494cf161"
                    ]
                },
                {
                    "id": "ab69693c-0c2e-4fed-98e0-e02f9f6912f0",
                    "firstName": "Samuel",
                    "lastName": "Lehn, BS",
                    "isCorresponding": false,
                    "affiliationIds": [
                        "2819909b-d808-4ecf-8ff5-df46494cf161"
                    ]
                },
                {
                    "id": "94151f3d-1e1a-4d4a-b6e8-77dda93fb63d",
                    "firstName": "Andrew",
                    "lastName": "Wong, MD, MS",
                    "isCorresponding": false,
                    "affiliationIds": [
                        "d266506a-1322-4076-8755-b32894f0ffc3"
                    ]
                }
            ],
            "affiliations": [
                {
                    "id": "d266506a-1322-4076-8755-b32894f0ffc3",
                    "institution": "University of Michigan, Michigan Medicine",
                    "department": "Internal Medicine",
                    "city": "Ann Arbor, Michigan"
                },
                {
                    "id": "2819909b-d808-4ecf-8ff5-df46494cf161",
                    "institution": "University of Michigan, Medical School",
                    "city": "Ann Arbor, Michigan"
                }
            ]
        },
        "sections": [
            {
                "id": "f97bf066-d803-430f-aa08-08a3f51fa0b8",
                "title": "Background",
                "content": "With national health expenditures projected to reach 19.7% of GDP by 2032 [[ref:827d175c-3d1d-413a-8f11-bc28ad59448d]], improving hospital operational efficiency is a critical priority. Effective hospital capacity management, which hinges on accurately predicting patient discharges, is essential for controlling costs and mitigating the negative patient outcomes associated with capacity strain [[ref:db74afcc-5ecf-4dea-9f8c-8f7462c2b180]]. While traditional machine learning models have shown success in predicting length of stay and discharge [[ref:b33964f9-7729-4ba4-9346-60051103970c]], their \"black box\" nature often limits clinical adoption due to a lack of explainability.\n\nLarge Language Models (LLMs) represent a promising new approach, demonstrating an ability to encode and apply complex clinical knowledge [[ref:a5274514-da89-4708-91f1-72b990cb52d2]]. However, current LLM evaluations in healthcare have largely focused on knowledge-based tasks rather than practical operational applications [[ref:8393832c-fb04-4443-b808-c1b0ddef19be]]. This study aims to address this gap by evaluating the performance of LLMs in predicting hospital discharges. Our objective is to test the ability of Large Language Models (LLMs) to predict same-day patient discharges by leveraging medical notes from the prior day up to 6 a.m. We aim to demonstrate that this specific approach can significantly improve predictive accuracy and, crucially, provide the explainable reasoning necessary to support clinical and administrative decision-making.",
                "userNotes": "# Overarching Goal of Paper\n- Introducing data on the use of LLMs in discharge prediction in hospitalized patients. We are introducing data that shows that inference time interventions, especially prompting, can improve LLM performance in prediction. \n\n# Formatting\n- Introduction to the current ML/AI landscape and historical context. Introduction of LLMs in healthcare.\n- Current knowledge gaps for AI/LLMs in healthcare.\n- What we present in this paper. \n\n# Key points\n- You do not need to use every reference\n- BE BRIEF. I only have 3000 characters for the whole paper\n",
                "versions": [
                    {
                        "id": "d6d5c265-59d9-436d-b0cd-f0e8ae14c336",
                        "timestamp": 1764617472097,
                        "content": "With national health expenditures projected to reach 19.7% of GDP by 2032 [[ref:827d175c-3d1d-413a-8f11-bc28ad59448d]], improving hospital operational efficiency is a critical priority. Effective hospital capacity management, which hinges on accurately predicting patient discharges, is essential for controlling costs and mitigating the negative patient outcomes associated with capacity strain [[ref:db74afcc-5ecf-4dea-9f8c-8f7462c2b180]]. While traditional machine learning models have shown success in predicting length of stay and discharge [[ref:b33964f9-7729-4ba4-9346-60051103970c]], their \"black box\" nature often limits clinical adoption due to a lack of explainability.\n\nLarge Language Models (LLMs) represent a promising new approach, demonstrating an ability to encode and apply complex clinical knowledge [[ref:a5274514-da89-4708-91f1-72b990cb52d2]]. However, current LLM evaluations in healthcare have largely focused on knowledge-based tasks rather than practical operational applications [[ref:8393832c-fb04-4443-b808-c1b0ddef19be]]. This study aims to address this gap by evaluating the performance of LLMs in predicting hospital discharges. Our objective is to demonstrate that inference-time interventions, specifically prompt engineering, can significantly improve predictive accuracy and, crucially, provide explainable reasoning to support clinical and administrative decision-making.",
                        "notes": "# Overarching Goal of Paper\n- Introducing data on the use of LLMs in discharge prediction in hospitalized patients. We are introducing data that shows that inference time interventions, especially prompting, can improve LLM performance in prediction. \n\n# Formatting\n- Introduction to the current ML/AI landscape and historical context. Introduction of LLMs in healthcare.\n- Current knowledge gaps for AI/LLMs in healthcare.\n- What we present in this paper. \n\n# Key points\n- You do not need to use every reference\n- BE BRIEF. I only have 3000 characters for the whole paper\n",
                        "commitMessage": "Auto-save before AI Refinement"
                    }
                ],
                "lastModified": 1764618627472,
                "useReferences": true
            },
            {
                "id": "ef442d7a-ca02-493c-94ea-c015123874c5",
                "title": "Methods",
                "content": "This single-center retrospective study included adults discharged in 2024 with an inpatient length of stay of 2-14 days.\n\nFor each admission, the primary outcome was discharge on a randomly selected \"index date.\" The text corpus comprised multidisciplinary clinical notes (physician, social work, physical therapy, case management) from the from the day preceding the index date through 6:00 AM on the index date. We created patient-disjoint training (n=995) and test (n=1,000) sets, both with an imbalanced 20% positive class (discharge day) distribution to reflect clinical reality. Samples without note text in their range was removed.\n\nWe compared manual and automated prompt engineering for a large language model (LLM). The manual approach involved refining a prompt via qualitative error analysis on the training set, while the automated approach used an optimization algorithm on a balanced training subset. [[ref:84f2e81c-88b2-4394-8468-9412e0aef12a]] The LLM generated a JSON output with a binary prediction and rationale.\n\nWe evaluated test set performance using F1-score, sensitivity, and specificity. The final classification was a majority vote across three independent runs to stabilize predictions. We calculated 95% confidence intervals for all metrics via 1,000 bootstrap replicates.",
                "userNotes": "# Population\n- Hospitalized patients in 2024 at Michigan Medicine who discharged in 2024\n- Removed same day discharges. Kept only patient's with an inpatient length of stay between 2-14 days. This was to allow for the presence of documentations and to remove outliers of people with long LOS. \n\n# Dataset collection\n- For each patient, included a random day in their hospital course, some of which was their day of discharge.\n- Given the imbalance of more people with NO discharge on their random day, we split the sample to include 20% same day discharge (with their randomly picked day) and 80% not same day discharge. \n- Generated text that included notes from the day prior of the randomly picked day up to 6am of the randomly picked day. Included physician/provider notes, social work notes, physical therapist notes, case manager notes\n- We then picked a random sample and removed samples where there were no medical notes\n- Train dataset: 995 samples\n- Test dataset: 1000 samples (none of which that had CSNs that were in the train dataset)\n\n# Performance Measures\n- Dataset has samples with text of the medical notes. LLM outputed a JSON output with a \"reasoning\" key and a \"prediction\" key. The prediction key was 0 or 1, where 0 is no predicted discharge on the random date and 1 is yes for predicting discharge.\n- Compared the predicted discharge with the known discharge integer\n- Key measures were F1 (binary) (given the imbalanced set). Also measured sensitivity and specificity.\n- For final performance measures, we used the majority prediction based on 3 runs for each sample. Then performed bootstraping with 1000. \n\n# Manual Prompt Engineering\n- Initial basic prompt and subsequent performance using GPT-5 on the train dataset. We then did a qualitative analysis of where the LLMs went wrong. \n- We then created a new prompt based on the qualitative analysis and tested on the test dataset. \n\n# Prompt Gradient Decent\n- Created custom code base to have LLMs automatically optimize the prompt based on prediction of discharge with the known discharge. Went through multiple rounds of prompt optimization. \n- Used a sample from the train set for prompt optimization. Balanced the dataset to include 50% discharge on random day and 50% not discharge on random day\n\n# Key points\n- We have limited space for this submission, so be brief and concise.",
                "versions": [
                    {
                        "id": "a1633aec-e466-43a1-b04b-1971ca7d4e2c",
                        "timestamp": 1764624507732,
                        "content": "This single-center retrospective study included adults discharged in 2024 with an inpatient length of stay of 2-14 days.\n\nFor each admission, the primary outcome was discharge on a randomly selected \"index date.\" The text corpus comprised multidisciplinary clinical notes (physician, social work, physical therapy, case management) from the 24 hours preceding 6:00 AM on the index date. We created patient-disjoint training (n=995) and test (n=1,000) sets, both with an imbalanced 20% positive class (discharge day) distribution to reflect clinical reality. Samples without note text in their range was removed.\n\nWe compared manual and automated prompt engineering for a large language model (LLM). The manual approach involved refining a prompt via qualitative error analysis on the training set, while the automated approach used an optimization algorithm on a balanced training subset.[[ref:84f2e81c-88b2-4394-8468-9412e0aef12a]] The LLM generated a JSON output with a binary prediction and rationale.\n\nWe evaluated test set performance using F1-score, sensitivity, and specificity. The final classification was a majority vote across three independent runs to stabilize predictions. We calculated 95% confidence intervals for all metrics via 1,000 bootstrap replicates.",
                        "notes": "# Population\n- Hospitalized patients in 2024 at Michigan Medicine who discharged in 2024\n- Removed same day discharges. Kept only patient's with an inpatient length of stay between 2-14 days. This was to allow for the presence of documentations and to remove outliers of people with long LOS. \n\n# Dataset collection\n- For each patient, included a random day in their hospital course, some of which was their day of discharge.\n- Given the imbalance of more people with NO discharge on their random day, we split the sample to include 20% same day discharge (with their randomly picked day) and 80% not same day discharge. \n- Generated text that included notes from the day prior of the randomly picked day up to 6am of the randomly picked day. Included physician/provider notes, social work notes, physical therapist notes, case manager notes\n- We then picked a random sample and removed samples where there were no medical notes\n- Train dataset: 995 samples\n- Test dataset: 1000 samples (none of which that had CSNs that were in the train dataset)\n\n# Performance Measures\n- Dataset has samples with text of the medical notes. LLM outputed a JSON output with a \"reasoning\" key and a \"prediction\" key. The prediction key was 0 or 1, where 0 is no predicted discharge on the random date and 1 is yes for predicting discharge.\n- Compared the predicted discharge with the known discharge integer\n- Key measures were F1 (binary) (given the imbalanced set). Also measured sensitivity and specificity.\n- For final performance measures, we used the majority prediction based on 3 runs for each sample. Then performed bootstraping with 1000. \n\n# Manual Prompt Engineering\n- Initial basic prompt and subsequent performance using GPT-5 on the train dataset. We then did a qualitative analysis of where the LLMs went wrong. \n- We then created a new prompt based on the qualitative analysis and tested on the test dataset. \n\n# Prompt Gradient Decent\n- Created custom code base to have LLMs automatically optimize the prompt based on prediction of discharge with the known discharge. Went through multiple rounds of prompt optimization. \n- Used a sample from the train set for prompt optimization. Balanced the dataset to include 50% discharge on random day and 50% not discharge on random day\n\n# Key points\n- We have limited space for this submission, so be brief and concise.",
                        "commitMessage": "Auto-save before AI Refinement"
                    },
                    {
                        "id": "f6209331-5dce-48e3-93a3-7f2bd262f1cf",
                        "timestamp": 1764624394996,
                        "content": "This retrospective cohort study included adult patients discharged in 2024 from a single academic medical center. We included patients with an inpatient length of stay between 2 and 14 days to ensure sufficient clinical documentation and exclude outliers.\n\nFor each admission, a single random inpatient day was selected as the index date. The primary outcome was whether discharge occurred on that index date. We compiled a text corpus for each patient, including all physician, social work, physical therapy, and case management notes documented in the 24 hours preceding 6:00 AM on the index date. We created a training set (n=995) and a held-out test set (n=1,000) with no patient overlap. To reflect clinical reality, both datasets were structured with an imbalanced class distribution, containing 20% samples from an actual discharge day and 80% from a non-discharge day.\n\nWe developed a two-stage prompt engineering process for a large language model (LLM). First, an initial prompt was manually refined based on a qualitative error analysis of model outputs on the training set. Second, we used an automated prompt optimization algorithm on a balanced subset of the training data to further improve performance. [[ref:84f2e81c-88b2-4394-8468-9412e0aef12a]] The LLM generated a structured JSON output with a binary discharge prediction and a free-text rationale.\n\nModel performance on the test set was primarily evaluated using the binary F1-score, supplemented by sensitivity and specificity. To stabilize predictions, the final classification for each sample was determined by a majority vote across three independent runs. We calculated 95% confidence intervals for all metrics using 1,000 bootstrap replicates.",
                        "notes": "# Population\n- Hospitalized patients in 2024 at Michigan Medicine who discharged in 2024\n- Removed same day discharges. Kept only patient's with an inpatient length of stay between 2-14 days. This was to allow for the presence of documentations and to remove outliers of people with long LOS. \n\n# Dataset collection\n- For each patient, included a random day in their hospital course, some of which was their day of discharge.\n- Given the imbalance of more people with NO discharge on their random day, we split the sample to include 20% same day discharge (with their randomly picked day) and 80% not same day discharge. \n- Generated text that included notes from the day prior of the randomly picked day up to 6am of the randomly picked day. Included physician/provider notes, social work notes, physical therapist notes, case manager notes\n- We then picked a random sample and removed samples where there were no medical notes\n- Train dataset: 995 samples\n- Test dataset: 1000 samples (none of which that had CSNs that were in the train dataset)\n\n# Performance Measures\n- Dataset has samples with text of the medical notes. LLM outputed a JSON output with a \"reasoning\" key and a \"prediction\" key. The prediction key was 0 or 1, where 0 is no predicted discharge on the random date and 1 is yes for predicting discharge.\n- Compared the predicted discharge with the known discharge integer\n- Key measures were F1 (binary) (given the imbalanced set). Also measured sensitivity and specificity.\n- For final performance measures, we used the majority prediction based on 3 runs for each sample. Then performed bootstraping with 1000. \n\n# Manual Prompt Engineering\n- Initial basic prompt and subsequent performance using GPT-5 on the train dataset. We then did a qualitative analysis of where the LLMs went wrong. \n- We then created a new prompt based on the qualitative analysis and tested on the test dataset. \n\n# Prompt Gradient Decent\n- Created custom code base to have LLMs automatically optimize the prompt based on prediction of discharge with the known discharge. Went through multiple rounds of prompt optimization. \n- Used a sample from the train set for prompt optimization. Balanced the dataset to include 50% discharge on random day and 50% not discharge on random day\n\n# Key points\n- We have limited space for this submission, so be brief and concise.",
                        "commitMessage": "Auto-save before AI Refinement"
                    },
                    {
                        "id": "9af631c3-4117-4208-aa98-455648588cfa",
                        "timestamp": 1764618295033,
                        "content": "# Methods\nThis retrospective cohort study included adult patients hospitalized at a single academic medical center who were discharged in 2024. To ensure sufficient documentation and remove outliers, we included only patients with an inpatient length of stay between 2 and 14 days.\n\nFor each qualifying patient, we selected a single, random inpatient day. The primary outcome was whether the patient was discharged on that selected day. We compiled a text corpus for each sampled day, consisting of all physician, social work, physical therapy, and case management notes documented in the 24 hours prior to 6:00 AM on that day. From this collection, we created a training dataset (n=995) and a test dataset (n=1000), ensuring no patient overlap between the sets. To simulate a realistic clinical scenario, both datasets were sampled to contain an imbalanced class distribution: 20% of samples were from a patient's actual discharge day, and 80% were not.\n\nWe utilized a large language model (LLM) to predict discharge. The LLM processed the text corpus and generated a structured JSON output containing a binary prediction (1=discharge, 0=no discharge) and a free-text \"reasoning\" field. Prompt engineering involved an initial manual refinement based on a qualitative error analysis on the training set, followed by an automated prompt optimization algorithm that iteratively refined the prompt using a balanced subset of the training data.\n\nModel performance was primarily evaluated using the binary F1-score, supplemented by sensitivity and specificity. To ensure robust evaluation on the test set, the final prediction for each sample was determined by a majority vote from three independent runs. We calculated 95% confidence intervals for all performance metrics using 1,000 bootstrap replicates.",
                        "notes": "# Population\n- Hospitalized patients in 2024 at Michigan Medicine who discharged in 2024\n- Removed same day discharges. Kept only patient's with an inpatient length of stay between 2-14 days. This was to allow for the presence of documentations and to remove outliers of people with long LOS. \n\n# Dataset collection\n- For each patient, included a random day in their hospital course, some of which was their day of discharge.\n- Given the imbalance of more people with NO discharge on their random day, we split the sample to include 20% same day discharge (with their randomly picked day) and 80% not same day discharge. \n- Generated text that included notes from the day prior of the randomly picked day up to 6am of the randomly picked day. Included physician/provider notes, social work notes, physical therapist notes, case manager notes\n- We then picked a random sample and removed samples where there were no medical notes\n- Train dataset: 995 samples\n- Test dataset: 1000 samples (none of which that had CSNs that were in the train dataset)\n\n# Performance Measures\n- Dataset has samples with text of the medical notes. LLM outputed a JSON output with a \"reasoning\" key and a \"prediction\" key. The prediction key was 0 or 1, where 0 is no predicted discharge on the random date and 1 is yes for predicting discharge.\n- Compared the predicted discharge with the known discharge integer\n- Key measures were F1 (binary) (given the imbalanced set). Also measured sensitivity and specificity.\n- For final performance measures, we used the majority prediction based on 3 runs for each sample. Then performed bootstraping with 1000. \n\n# Manual Prompt Engineering\n- Initial basic prompt and subsequent performance using GPT-5 on the train dataset. We then did a qualitative analysis of where the LLMs went wrong. \n- We then created a new prompt based on the qualitative analysis and tested on the test dataset. \n\n# Prompt Gradient Decent\n- Created custom code base to have LLMs automatically optimize the prompt based on prediction of discharge with the known discharge. Went through multiple rounds of prompt optimization. \n- Used a sample from the train set for prompt optimization. Balanced the dataset to include 50% discharge on random day and 50% not discharge on random day\n\n# Key points\n- We have limited space for this submission, so be brief and concise.",
                        "commitMessage": "Auto-save before AI Draft"
                    },
                    {
                        "id": "554f7e82-d3d0-480f-82b2-85753e462d0f",
                        "timestamp": 1764618206470,
                        "content": "s",
                        "notes": "# Population\n- Hospitalized patients in 2024 at Michigan Medicine who discharged in 2024\n- Removed same day discharges. Kept only patient's with an inpatient length of stay between 2-14 days. This was to allow for the presence of documentations and to remove outliers of people with long LOS. \n\n# Dataset collection\n- For each patient, included a random day in their hospital course, some of which was their day of discharge.\n- Given the imbalance of more people with NO discharge on their random day, we split the sample to include 20% same day discharge (with their randomly picked day) and 80% not same day discharge. \n- Generated text that included notes from the day prior of the randomly picked day up to 6am of the randomly picked day. Included physician/provider notes, social work notes, physical therapist notes, case manager notes\n- We then picked a random sample and removed samples where there were no medical notes\n- Train dataset: 995 samples\n- Test dataset: 1000 samples (none of which that had CSNs that were in the train dataset)\n\n# Performance Measures\n- Dataset has samples with text of the medical notes. LLM outputed a JSON output with a \"reasoning\" key and a \"prediction\" key. The prediction key was 0 or 1, where 0 is no predicted discharge on the random date and 1 is yes for predicting discharge.\n- Compared the predicted discharge with the known discharge integer\n- Key measures were F1 (binary) (given the imbalanced set). Also measured sensitivity and specificity.\n- For final performance measures, we used the majority prediction based on 3 runs for each sample. Then performed bootstraping with 1000. \n\n# Manual Prompt Engineering\n- Initial basic prompt and subsequent performance using GPT-5 on the train dataset. We then did a qualitative analysis of where the LLMs went wrong. \n- We then created a new prompt based on the qualitative analysis and tested on the test dataset. \n\n# Prompt Gradient Decent\n- Created custom code base to have LLMs automatically optimize the prompt based on prediction of discharge with the known discharge. Went through multiple rounds of prompt optimization. \n- Used a sample from the train set for prompt optimization. Balanced the dataset to include 50% discharge on random day and 50% not discharge on random day",
                        "commitMessage": "Auto-save before AI Draft"
                    }
                ],
                "lastModified": 1764624676348,
                "useReferences": false
            },
            {
                "id": "77c2fe35-ffc9-4478-9344-0eddb6b3bb18",
                "title": "Results",
                "content": "The initial model using a basic prompt achieved a binary F1-score of 0.482 on the training data. On the test set, manual prompt refinement resulted in a binary F1-score of 0.463 [95% CI: 0.398, 0.527] and a sensitivity of 0.342 [CI: 0.284, 0.404]. Increasing the model's reasoning capacity to \"High Reasoning\" with the same manually refined prompt provided only marginal improvement, with a binary F1-score of 0.493 [CI: 0.432, 0.554].\n\nIn contrast, automated prompt optimization using Prompt Gradient Descent yielded a substantial performance increase. This final model achieved a binary F1-score of 0.624 [CI: 0.575, 0.669] and a macro F1-score of 0.739 [CI: 0.708, 0.767]. The improvement was primarily driven by a more than twofold increase in sensitivity to 0.709 [CI: 0.652, 0.764], while maintaining a high specificity of 0.815 [CI: 0.787, 0.842]. \n",
                "userNotes": "Overall Results\n- Improvement in prompt optimization\n\n\nMarkdown of expected table\n```| Model / Prompt                                                     | Dataset | F1 Binary                | F1 Macro                 | Sensitivity (Recall)       | Specificity              |\n|-------------------------------------------------------------------|---------|---------------------------|---------------------------|-----------------------------|---------------------------|\n| **GPT-5 Medium Reasoning — Basic Prompt**                         | TRAIN   | 0.4818                    | 0.6842                    | 0.3739                      | 0.9463                    |\n| **GPT-5 Medium Reasoning — Manual Refined Prompt**                | TEST    | 0.463 [0.398, 0.527]      | 0.671 [0.634, 0.708]      | 0.342 [0.284, 0.404]        | 0.956 [0.941, 0.969]      |\n| **GPT-5 High Reasoning — Manual Refined Prompt**                  | TEST    | 0.493 [0.432, 0.554]      | 0.688 [0.654, 0.723]      | 0.374 [0.318, 0.435]        | 0.953 [0.938, 0.967]      |\n| **GPT-5 Medium Reasoning — LLM Refined Prompt (Prompt Gradient Descent)** | TEST    | 0.624 [0.575, 0.669]      | 0.739 [0.708, 0.767]      | 0.709 [0.652, 0.764]        | 0.815 [0.787, 0.842]      |\n```",
                "versions": [],
                "lastModified": 1764622995515,
                "useReferences": true
            },
            {
                "id": "2ad2d160-0fb2-4ccf-a64b-21ba681aedfb",
                "title": "Conclusion",
                "content": "LLMs demonstrate significant potential for accurately predicting inpatient discharges. We found that model performance is enhanced through prompt engineering, with automated LLM-based prompt optimization presenting a rapid and scalable method. An advantage of LLMs over traditional machine learning models is their unique ability to generate interpretable reasoning for their predictions. This feature can offer clinicians and hospital administrators insight into specific patient-level barriers to discharge. For clinical practice, these actionable insights can facilitate more targeted and efficient discharge planning, potentially improving patient flow and optimizing resource allocation. Future research should focus on integrating these predictive tools into clinical workflows to prospectively evaluate their impact on care delivery and patient outcomes.",
                "userNotes": "# Message\n- LLMs have potential for accurately predicting discharge.\n- LLMs can have improved performance in complex medical discharge prediction when using prompt engineering techniques\n- Prompt formatting is key in improving performance\n- Automatic LLM based prompt optimization offers fast and scalable performance performance\n- LLMs offer the benefit over traditional ML methods in that they can offer insight into the reasoning of their predictions. Benefits of this includes accurate evaluation of barriers that can assist in discharge planning, etc",
                "versions": [
                    {
                        "id": "2883b7be-0136-4280-a28a-ca03723b3c44",
                        "timestamp": 1764623358643,
                        "content": "LLMs demonstrate significant potential for accurately predicting patient hospital discharges. Our findings reveal that model performance is substantially enhanced through advanced prompt engineering, with automated prompt optimization presenting a rapid and scalable method for improvement. A critical advantage of LLMs over traditional machine learning models is their unique ability to generate interpretable reasoning for their predictions. This feature offers clinicians and hospital administrators unprecedented insight into specific patient-level barriers to discharge. For clinical practice, these actionable insights can facilitate more targeted and efficient discharge planning, potentially improving patient flow and optimizing resource allocation. Future research should focus on integrating these predictive tools into clinical workflows to prospectively evaluate their impact on care delivery and patient outcomes.",
                        "notes": "# Message\n- LLMs have potential for accurately predicting discharge.\n- LLMs can have improved performance in complex medical discharge prediction when using prompt engineering techniques\n- Prompt formatting is key in improving performance\n- Automatic LLM based prompt optimization offers fast and scalable performance performance\n- LLMs offer the benefit over traditional ML methods in that they can offer insight into the reasoning of their predictions. Benefits of this includes accurate evaluation of barriers that can assist in discharge planning, etc",
                        "commitMessage": "Restored from 12/1/2025"
                    },
                    {
                        "id": "703fadf2-eaf1-479c-b7e8-5a6c91ac0361",
                        "timestamp": 1764623321623,
                        "content": "LLMs demonstrate significant potential for accurately predicting patient hospital discharges. Our findings reveal that model performance is substantially enhanced through advanced prompt engineering, with automated prompt optimization presenting a rapid and scalable method for improvement. A critical advantage of LLMs over traditional machine learning models is their unique ability to generate interpretable reasoning for their predictions. This feature offers clinicians and hospital administrators unprecedented insight into specific patient-level barriers to discharge. For clinical practice, these actionable insights can facilitate more targeted and efficient discharge planning, potentially improving patient flow and optimizing resource allocation. Future research should focus on integrating these predictive tools into clinical workflows to prospectively evaluate their impact on care delivery and patient outcomes.",
                        "notes": "# Message\n- LLMs have potential for accurately predicting discharge.\n- LLMs can have improved performance in complex medical discharge prediction when using prompt engineering techniques\n- Prompt formatting is key in improving performance\n- Automatic LLM based prompt optimization offers fast and scalable performance performance\n- LLMs offer the benefit over traditional ML methods in that they can offer insight into the reasoning of their predictions. Benefits of this includes accurate evaluation of barriers that can assist in discharge planning, etc",
                        "commitMessage": "Auto-save before AI Refinement"
                    }
                ],
                "lastModified": 1764623473788,
                "useReferences": true
            },
            {
                "id": "bc5033f0-1011-4be8-bc65-e1da18aa90d7",
                "title": "Learning Objectives",
                "content": "1.  Assess the potential of large language models to augment clinical judgment in discharge planning by providing explainable predictions, thereby improving hospital resource management (Systems-Based Practice).\n2.  Recognize key patient-specific factors identified by large language models that are critical for timely and safe hospital discharge, enhancing individualized patient care (Patient Care).",
                "userNotes": "Generate learning objectives based on the current manuscript draft\n\nInstructions from the Website\n- Learning Objectives (2 required) focused learning objectives, stating what the physician should be able to do after learning from the case presentation. Each learning objective should reflect one of the six ACGME Core Competencies. Objectives are action-oriented and should begin with words such as recognize, diagnose, assess, treat, distinguish, or manage. They should NOT begin with terms like \"know how to\" or \"understand.\" \n- Examples:\n   - Diagnose hip fracture when the plain X-rays are normal\n   - Recognize the clinical features of anorexia and bulimia in a male\n   - Assess health literacy in at-risk populations",
                "versions": [],
                "lastModified": 1764624012131,
                "useReferences": true
            }
        ],
        "references": [
            {
                "id": "827d175c-3d1d-413a-8f11-bc28ad59448d",
                "title": "National Health Expenditure Projections, 2023-32: Payer Trends Diverge As Pandemic-Related Policies Fade.",
                "authors": "Fiore Jacqueline A, Madison Andrew J, Poisal John A, Cuckler Gigi A, Smith Sheila D, Sisko Andrea M, Keehan Sean P, Rennie Kathryn E, Gross Alyssa C",
                "year": "2024",
                "publication": "Health affairs (Project Hope)",
                "doi": "10.1377/hlthaff.2024.00469",
                "summary": "",
                "abstract": "Health care spending growth is expected to outpace that of the gross domestic product (GDP) during the coming decade, resulting in a health share of GDP that reaches 19.7 percent by 2032 (up from 17.3 percent in 2022). National health expenditures are projected to have grown 7.5 percent in 2023, when the COVID-19 public health emergency ended. This reflects broad increases in the use of health care, which is associated with an estimated 93.1 percent of the population being insured that year. In 2024, Medicaid enrollment is projected to decline significantly as states continue their eligibility redeterminations. Simultaneously, private health insurance enrollment is projected to increase because of the extension of enhanced subsidies for direct-purchase health insurance under the Inflation Reduction Act (IRA) of 2022, as well as a temporary special enrollment period for qualified people losing Medicaid coverage (after eligibility redeterminations). Over the course of 2024-26, the IRA expands Medicare's drug benefit generosity and implements drug price negotiations for beneficiaries; concurrently, the extended enhanced subsidies for direct-purchase health insurance expire in 2026. During 2027-32, personal health care price inflation and growth in the use of health care services and goods contribute to projected health spending that grows at a faster rate than the rest of the economy.",
                "notes": "",
                "articleType": ""
            },
            {
                "id": "4588c178-1a6a-451a-ada2-5769c30bcb8b",
                "title": "The Potential Impact of Artificial Intelligence on Healthcare Spending",
                "authors": "Sahni Nikhil, Stein George, Zemmel Rodney, Cutler David",
                "year": "2023,1",
                "publication": "",
                "doi": "10.3386/w30857",
                "summary": "",
                "abstract": "The potential of artificial intelligence (AI) to simplify existing healthcare processes and create new, more efficient ones is a major topic of discussion in the industry. Yet healthcare lags other industries in AI adoption. In this paper, we estimate that wider adoption of AI could lead to savings of 5 to 10 percent in US healthcare spending—roughly $200 billion to $360 billion annually in 2019 dollars. These estimates are based on specific AI-enabled use cases that employ today’s technologies, are attainable within the next five years, and would not sacrifice quality or access. These opportunities could also lead to nonfinancial benefits such as improved healthcare quality, increased access, better patient experience, and greater clinician satisfaction. We further present case studies and discuss how to overcome the challenges to AI deployments. We conclude with a review of recent market trends that may shift the AI adoption trajectory toward a more rapid pace.",
                "notes": "",
                "articleType": "report"
            },
            {
                "id": "c9daf24b-d1ad-4c2a-932d-d1c5cbb5208c",
                "title": "Artificial Intelligence in U.S. Health Care Delivery.",
                "authors": "Sahni Nikhil R, Carrus Brandon",
                "year": "2023",
                "publication": "The New England journal of medicine",
                "doi": "10.1056/NEJMra2204673",
                "summary": "",
                "abstract": "The adoption of artificial intelligence (AI) and its impact on \nbusiness sectors happen in phases. The use of AI is advanced in many areas, \nincluding reinventing how a financial institution provides investment advice \nand products to its customers, offering “recommendation engines” that suggest \nthe next retail product to buy for a consumer who has just bought one item, and \ndeveloping driverless cars. In health care delivery, however, AI remains in the \nearly stages.\n AI adoption in health care delivery lags behind the use of AI in other business \nsectors for multiple reasons. Early AI took root in business sectors in which large \namounts of structured, quantitative data were available and the computer algo\nrithms, which are the heart of AI, could be trained on discrete outcomes — for \nexample, a customer looked at a product and bought it or did not buy it. Qualitative \ninformation, such as clinical notes and patients’ reports, are generally harder to \ninterpret, and multifactorial outcomes associated with clinical decision making \nmake algorithm training more difficult. Another challenge is embedding AI out\nput into the already complex clinical workflow. Furthermore, in our experience, \nthe environment in which some health care organizations operate often leads \nthese organizations to focus on near-term financial results at the cost of invest\nment in longer-term, innovative forms of technology such as AI. Health care orga\nnizations that prioritize innovation link investment decisions to “total mission \nvalue,” which includes both financial and nonfinancial factors such as quality \nimprovement, patient safety, patient experience, clinician satisfaction, and increased \naccess to care.\n We think that the need for AI to help improve health care delivery should no \nlonger be questioned, for many reasons. Take the case of the exponential increase \nin the collective body of medical knowledge required to treat a patient. In 1980, \nthis knowledge doubled every 7 years; in 2010, the doubling period was fewer than \n75 days.1 Today, what medical students learn in their first 3 years would be only \n6 percent of known medical information at the time of their graduation. Their \nknowledge could still be relevant but might not always be complete, and some of \nwhat they were taught will be outdated. AI has the potential to supplement a \nclinical team’s knowledge in order to ensure that patients everywhere receive the \nbest care possible. Bringing that potential to reality has not been easy, but there \nare some successes.\n There are signs of increased adoption. Economies of expertise — or the devel\nopment of more robust AI algorithms from more data — have become a key ac\ncelerant for a new subindustry, referred to as health care services and technology \n(e.g., software and platforms, data analytics, and payment services), which has the \nn engl j med 389;4 nejm.org July 27, 2023\n The New England Journal of Medicine is produced by NEJM Group, a division of the Massachusetts Medical Society.\n Downloaded from nejm.org at University of Michigan--Ann Arbor on December 1, 2025. \n Copyright © 2023 Massachusetts Medical Society. All rights reserved, including those for text and data mining, AI training, and similar technologies.\nArtificial Intelligence in U.S. Health Care\n potential in the next few years to be as large mon\netarily as the entire payer subindustry is today.2 The \ncoronavirus disease 2019 (Covid-19) pandemic \nhas also been a catalyst, prompting organiza\ntions to accelerate plans to digitalize and deploy \nAI. At the management and board levels of orga\nnizations, the recent public awareness of genera\ntive AI has increased conversations regarding AI. \nIn addition, the adoption of AI can have second\norder effects, such as alleviating part of the on\ngoing shortage of physicians and nurses.\n In this article, we discuss the emerging use \nof AI in health care delivery, which is defined as \ndirect and supportive functions related to the \nprovision of health care. By way of full disclosure, \nwe are both employed by a company that pro\nvides consulting services for public and private \norganizations in this area. We also examine the \nuse of AI in the domains of reimbursement, \nclinical operations, and quality and safety. Fi\nnally, we discuss the challenges that health care \norganizations are facing in deploying AI.",
                "notes": "",
                "articleType": "Review"
            },
            {
                "id": "56dee427-e9ac-47fe-a8bf-f82a07d678e0",
                "title": "Improving healthcare operations management with machine learning",
                "authors": "Pianykh Oleg S., Guitron Steven, Parke Darren, Zhang Chengzhao, Pandharipande Pari, Brink James, Rosenthal Daniel",
                "year": "2020,5,18",
                "publication": "Nature Machine Intelligence",
                "doi": "10.1038/s42256-020-0176-3",
                "summary": "",
                "abstract": "Healthcare institutions need modern and powerful technology to provide high-quality, cost-effective care to patients. However, despite the considerable progress in the computerization and digitization of medicine, efficient and robust management tools have yet to materialize. One important reason for this is the extreme complexity and variability of healthcare operations, the needs of which have outgrown conventional management. Machine learning algorithms, scalable and adaptive to complex patterns, may be particularly well suited to solving these problems. Two major advantages of machine learning—the power of building strong models from a large number of weakly predictive features, and the ability to identify key factors in complex feature sets—have a particularly direct connection to the principal operational challenges. The main goal of this work was to study this relationship using two major types of operational problems: predicting operational events, and identifying key workflow drivers. Using practical examples, we demonstrate how machine learning can improve human ability to understand and manage healthcare operations, leading to more efficient healthcare.",
                "notes": "",
                "articleType": "journal article"
            },
            {
                "id": "2cc22ff6-ce2b-4642-a2c4-aa4b95c111ab",
                "title": "Machine Learning Operations in Health Care: A Scoping Review.",
                "authors": "Rajagopal Anjali, Ayanian Shant, Ryu Alexander J, Qian Ray, Legler Sean R, Peeler Eric A, Issa Meltiady, Coons Trevor J, Kawamoto Kensaku",
                "year": "2024",
                "publication": "Mayo Clinic proceedings. Digital health",
                "doi": "10.1016/j.mcpdig.2024.06.009",
                "summary": "",
                "abstract": "The use of machine learning tools in health care is rapidly expanding. However, the processes that support these tools in deployment, that is, machine learning operations, are still emerging. The purpose of this work was not only to provide a comprehensive synthesis of existing literature in the field but also to identify gaps and offer insights for adoption in clinical practice. A scoping review was conducted using the MEDLINE, PubMed, Google Scholar, Embase, and Scopus databases. We used MeSH and non-MeSH search terms to identify pertinent articles, with the authors performing 2 screening phases and assigning relevance scores: 148 English language articles most salient to the review were eligible for inclusion; 98 offered the most unique information and these were supplemented by 50 additional sources, yielding 148 references. From the 148 references, we distilled 7 key topic areas, based on a synthesis of the available literature and how that aligned with practitioner needs. The 7 topic areas were machine learning model monitoring; automated retraining systems; ethics, equity, and bias; clinical workflow integration; infrastructure, human resources, and technology stack; regulatory considerations; and financial considerations. This review provides an overview of best practices and knowledge gaps of this domain in health care and identifies the strengths and weaknesses of the literature, which may be useful to health care machine learning practitioners and consumers.",
                "notes": "",
                "articleType": "Review"
            },
            {
                "id": "db74afcc-5ecf-4dea-9f8c-8f7462c2b180",
                "title": "The Association Between Hospital Capacity Strain and Inpatient Outcomes in Highly Developed Countries: A Systematic Review.",
                "authors": "Eriksson Carl O, Stoner Ryan C, Eden Karen B, Newgard Craig D, Guise Jeanne-Marie",
                "year": "2017",
                "publication": "Journal of general internal medicine",
                "doi": "10.1007/s11606-016-3936-3",
                "summary": "",
                "abstract": "BACKGROUND: Increases in patient needs can strain hospital resources, which may worsen care quality and outcomes. This systematic literature review sought to understand whether hospital capacity strain is associated with worse health outcomes for hospitalized patients and to evaluate benefits and harms of health system interventions to improve care quality during times of hospital capacity strain.\n\nMETHODS: Parallel searches were conducted in MEDLINE, CINAHL, the Cochrane Library, and reference lists from 1999-2015. Two reviewers assessed study eligibility. We included English-language studies describing the association between capacity strain (high census, acuity, turnover, or an indirect measure of strain such as delayed admission) and health outcomes or intermediate outcomes for children and adults hospitalized in highly developed countries. We also included studies of health system interventions to improve care during times of capacity strain. Two reviewers extracted data and assessed risk of bias using the Newcastle-Ottawa Score for observational studies and the Cochrane Collaboration Risk of Bias Assessment Tool for experimental studies.\n\nRESULTS: Of 5,702 potentially relevant studies, we included 44 observational and 8 experimental studies. There was marked heterogeneity in the metrics used to define capacity strain, hospital settings, and overall study quality. Mortality increased during times of capacity strain in 18 of 30 studies and in 9 of 12 studies in intensive care unit settings. No experimental studies were randomized, and none demonstrated an improvement in health outcomes after implementing the intervention. The pediatric literature is very limited; only six observational studies included children. There was insufficient study homogeneity to perform meta-analyses.\n\nDISCUSSION: In highly developed countries, hospital capacity strain is associated with increased mortality and worsened health outcomes. Evidence-based solutions to improve outcomes during times of capacity strain are needed.",
                "notes": "",
                "articleType": "Systematic Review"
            },
            {
                "id": "b24fb92b-868c-48d9-b934-d6f220e17cf7",
                "title": "Hospital capacity management decisions: Emphasis on cost control and quality enhancement",
                "authors": "Li Ling, Benton W.C",
                "year": "2003,5",
                "publication": "European Journal of Operational Research",
                "doi": "10.1016/S0377-2217(02)00225-4",
                "summary": "",
                "abstract": "This paper empirically examines the effects of several key hospital demographic factors (hospital size, location, teaching involvement) and service characteristics on hospital capacity management decisions, and the effects of hospital capacity resource management choices on cost control and quality enhancement. In this research structural equation modeling (SEM) was used as the research vehicle. SEM modeling measures multiple relationships among independent and dependent variables, thus accommodating aggregated dependent relationships simultaneously in one comprehensive model. Several managerial insights emerged from the research: (a) outpatient service, health care network, workforce competence, and information technology are identified as key indicators of hospital capacity resource management decisions in the current health care environment; (b) hospital cost control is influenced by equipment/technology and workforce decisions; (c) hospital quality performance is associated with equipment/technology decisions, and positively but not strongly related to workforce decisions; (d) location, size and service mix have a significant impact on hospital capacity decisions; and (e) staff training, staff competence, and job enlargement are key operational indicators influencing workforce development/management decisions.",
                "notes": "",
                "articleType": "journal article"
            },
            {
                "id": "196c6489-e0d4-4e20-a9bd-c27bb7899929",
                "title": "Use of Hospital Capacity Command Centers to Improve Patient Flow and Safety: A Scoping Review.",
                "authors": "Franklin Brian J, Mueller Stephanie K, Bates David W, Gandhi Tejal K, Morris Charles A, Goralnick Eric",
                "year": "2022",
                "publication": "Journal of patient safety",
                "doi": "10.1097/PTS.0000000000000976",
                "summary": "",
                "abstract": "OBJECTIVES: Delayed emergency department (ED) and hospital patient throughput is recognized as a critical threat to patient safety. Increasingly, hospitals are investing significantly in deploying command centers, long used in airlines and the military, to proactively manage hospital-wide patient flow. This scoping review characterizes the evidence related to hospital capacity command centers (CCCs) and synthesizes current data regarding their implementation.\n\nMETHODS: As no consensus definition exists for CCCs, we characterized them as units (i) involving interdisciplinary, permanently colocated teams, (ii) using real-time data, and (iii) managing 2 or more patient flow functions (e.g., bed management, transfers, discharge planning, etc.), to distinguish CCCs from transfer centers. We undertook a scoping review of the medical and gray literature published through April 2019 related to CCCs meeting these criteria.\n\nRESULTS: We identified 8 eligible articles (including 4 peer-reviewed studies) describing 7 CCCs of varying designs. The most common CCC outcome measures related to transfer volume (n = 5) and ED boarding (n = 4). Several CCCs also monitored patient-level clinical parameters. Although all articles reported performance improvements, heterogeneity in CCC design and evidence quality currently restricts generalizability of findings.\n\nCONCLUSIONS: Numerous anecdotal accounts suggest that CCCs are being widely deployed in an effort to improve hospital patient flow and safety, yet peer-reviewed evidence regarding their design and effectiveness is in its earliest stages. The costs, objectives, and growing deployment of CCCs merit an investment in rigorous research to better measure their processes and outcomes. We propose a standard definition, conceptual framework, research priorities, and reporting standards to guide future investigation of CCCs.",
                "notes": "",
                "articleType": "Scoping Review"
            },
            {
                "id": "e486e4a5-8ebc-4192-ba0e-87db6ce31f13",
                "title": "Introducing an electronic tracking tool into daily multidisciplinary discharge rounds on a medicine service: a quality improvement project to reduce length of stay.",
                "authors": "Meo Nicholas, Paul Evan, Wilson Christopher, Powers Janice, Magbual Marinette, Miles Kari Mae",
                "year": "2018",
                "publication": "BMJ open quality",
                "doi": "10.1136/bmjoq-2017-000174",
                "summary": "This quality improvement project addressed inefficient discharge coordination on a medicine service by introducing an electronic tool into daily multidisciplinary discharge rounds. The tool standardized the capture and real-time display of critical patient information for physicians, nurses, and social workers. This intervention significantly reduced the average length of stay by 1.4 days (21.1%) without increasing readmission rates, highlighting the benefits of optimized team communication for discharge planning.",
                "abstract": "BACKGROUND: Inefficient coordination of care around discharge can increase length of stay, lead to ineffective transitions and contribute an unnecessary cost burden to patients and hospital systems. Multidisciplinary discharge rounds can improve situational awareness among team members leading to more efficient and better coordinated care. This project aimed to standardise the daily discharge rounds occurring on a medicine service to reduce length of stay. Participants included physicians, nurses and social workers.\n\nMETHODS: A key driver diagram was developed to understand drivers of length of stay. Improving multidisciplinary care coordination was targeted as an initial area of focus. Stakeholder interviews were held to understand current participants challenges with the daily discharge rounds process. Baseline assessment included a review of discharges for 6 weeks before the initial intervention. A Plan Do Study Act quality improvement framework was used to implement change.\n\nINTERVENTION: An electronic tool was developed which highlighted critical information to be captured during discharge rounds on each current inpatient in a standardised fashion. Information was reviewed and solicited from care teams by a facilitator, then edited and displayed in real time to all team members by a scribe.\n\nRESULTS: The average length of stay decreased by 1.4 days (p<0.05), an improvement of 21.1%. There was no measured increase on readmission rate during the intervention period.\n\nCONCLUSION: An electronic tool to standardise information gathered among team members in daily discharge rounds led to improvements in length of stay. Multidisciplinary discharge rounds are an important venue for discharge planning across inpatient care teams and efforts to optimise communication between team members can improve care.",
                "notes": "",
                "articleType": ""
            },
            {
                "id": "736f6bb9-b0b0-4143-bae9-4cb7399879d4",
                "title": "Scalable and accurate deep learning with electronic health records.",
                "authors": "Rajkomar Alvin, Oren Eyal, Chen Kai, Dai Andrew M, Hajaj Nissan, Hardt Michaela, Liu Peter J, Liu Xiaobing, Marcus Jake, Sun Mimi, Sundberg Patrik, Yee Hector, Zhang Kun, Zhang Yi, Flores Gerardo, Duggan Gavin E, Irvine Jamie, Le Quoc, Litsch Kurt, Mossin Alexander, Tansuwan Justin, Wang De, Wexler James, Wilson Jimbo, Ludwig Dana, Volchenboum Samuel L, Chou Katherine, Pearson Michael, Madabushi Srinivasan, Shah Nigam H, Butte Atul J, Howell Michael D, Cui Claire, Corrado Greg S, Dean Jeffrey",
                "year": "2018",
                "publication": "NPJ digital medicine",
                "doi": "10.1038/s41746-018-0029-1",
                "summary": "",
                "abstract": "Predictive modeling with electronic health record (EHR) data is anticipated to drive personalized medicine and improve healthcare quality. Constructing predictive statistical models typically requires extraction of curated predictor variables from normalized EHR data, a labor-intensive process that discards the vast majority of information in each patient's record. We propose a representation of patients' entire raw EHR records based on the Fast Healthcare Interoperability Resources (FHIR) format. We demonstrate that deep learning methods using this representation are capable of accurately predicting multiple medical events from multiple centers without site-specific data harmonization. We validated our approach using de-identified EHR data from two US academic medical centers with 216,221 adult patients hospitalized for at least 24 h. In the sequential format we propose, this volume of EHR data unrolled into a total of 46,864,534,945 data points, including clinical notes. Deep learning models achieved high accuracy for tasks such as predicting: in-hospital mortality (area under the receiver operator curve [AUROC] across sites 0.93-0.94), 30-day unplanned readmission (AUROC 0.75-0.76), prolonged length of stay (AUROC 0.85-0.86), and all of a patient's final discharge diagnoses (frequency-weighted AUROC 0.90). These models outperformed traditional, clinically-used predictive models in all cases. We believe that this approach can be used to create accurate and scalable predictions for a variety of clinical scenarios. In a case study of a particular prediction, we demonstrate that neural networks can be used to identify relevant information from the patient's chart.",
                "notes": "",
                "articleType": ""
            },
            {
                "id": "961723cb-e14e-4ea8-ba70-399a4baf7984",
                "title": "Analysis of length of hospital stay using electronic health records: A statistical and data mining approach.",
                "authors": "Baek Hyunyoung, Cho Minsu, Kim Seok, Hwang Hee, Song Minseok, Yoo Sooyoung",
                "year": "2018",
                "publication": "PloS one",
                "doi": "10.1371/journal.pone.0195901",
                "summary": "",
                "abstract": "BACKGROUND: The length of stay (LOS) is an important indicator of the efficiency of hospital management. Reduction in the number of inpatient days results in decreased risk of infection and medication side effects, improvement in the quality of treatment, and increased hospital profit with more efficient bed management. The purpose of this study was to determine which factors are associated with length of hospital stay, based on electronic health records, in order to manage hospital stay more efficiently.\n\nMATERIALS AND METHODS: Research subjects were retrieved from a database of patients admitted to a tertiary general university hospital in South Korea between January and December 2013. Patients were analyzed according to the following three categories: descriptive and exploratory analysis, process pattern analysis using process mining techniques, and statistical analysis and prediction of LOS.\n\nRESULTS: Overall, 55% (25,228) of inpatients were discharged within 4 days. The department of rehabilitation medicine (RH) had the highest average LOS at 15.9 days. Of all the conditions diagnosed over 250 times, diagnoses of I63.8 (cerebral infarction, middle cerebral artery), I63.9 (infarction of middle cerebral artery territory) and I21.9 (myocardial infarction) were associated with the longest average hospital stay and high standard deviation. Patients with these conditions were also more likely to be transferred to the RH department for rehabilitation. A range of variables, such as transfer, discharge delay time, operation frequency, frequency of diagnosis, severity, bed grade, and insurance type was significantly correlated with the LOS.\n\nCONCLUSIONS: Accurate understanding of the factors associating with the LOS and progressive improvements in processing and monitoring may allow more efficient management of the LOS of inpatients.",
                "notes": "",
                "articleType": "Research Support, Non-U.S. Gov't"
            },
            {
                "id": "b33964f9-7729-4ba4-9346-60051103970c",
                "title": "Machine Learning-Based Hospital Discharge Prediction for Patients With Cardiovascular Diseases: Development and Usability Study.",
                "authors": "Ahn Imjin, Gwon Hansle, Kang Heejun, Kim Yunha, Seo Hyeram, Choi Heejung, Cho Ha Na, Kim Minkyoung, Jun Tae Joon, Kim Young-Hak",
                "year": "2021",
                "publication": "JMIR medical informatics",
                "doi": "10.2196/32662",
                "summary": "",
                "abstract": "BACKGROUND: Effective resource management in hospitals can improve the quality of medical services by reducing labor-intensive burdens on staff, decreasing inpatient waiting time, and securing the optimal treatment time. The use of hospital processes requires effective bed management; a stay in the hospital that is longer than the optimal treatment time hinders bed management. Therefore, predicting a patient's hospitalization period may support the making of judicious decisions regarding bed management.\n\nOBJECTIVE: First, this study aims to develop a machine learning (ML)-based predictive model for predicting the discharge probability of inpatients with cardiovascular diseases (CVDs). Second, we aim to assess the outcome of the predictive model and explain the primary risk factors of inpatients for patient-specific care. Finally, we aim to evaluate whether our ML-based predictive model helps manage bed scheduling efficiently and detects long-term inpatients in advance to improve the use of hospital processes and enhance the quality of medical services.\n\nMETHODS: We set up the cohort criteria and extracted the data from CardioNet, a manually curated database that specializes in CVDs. We processed the data to create a suitable data set by reindexing the date-index, integrating the present features with past features from the previous 3 years, and imputing missing values. Subsequently, we trained the ML-based predictive models and evaluated them to find an elaborate model. Finally, we predicted the discharge probability within 3 days and explained the outcomes of the model by identifying, quantifying, and visualizing its features.\n\nRESULTS: We experimented with 5 ML-based models using 5 cross-validations. Extreme gradient boosting, which was selected as the final model, accomplished an average area under the receiver operating characteristic curve score that was 0.865 higher than that of the other models (ie, logistic regression, random forest, support vector machine, and multilayer perceptron). Furthermore, we performed feature reduction, represented the feature importance, and assessed prediction outcomes. One of the outcomes, the individual explainer, provides a discharge score during hospitalization and a daily feature influence score to the medical team and patients. Finally, we visualized simulated bed management to use the outcomes.\n\nCONCLUSIONS: In this study, we propose an individual explainer based on an ML-based predictive model, which provides the discharge probability and relative contributions of individual features. Our model can assist medical teams and patients in identifying individual and common risk factors in CVDs and can support hospital administrators in improving the management of hospital beds and other resources.",
                "notes": "",
                "articleType": ""
            },
            {
                "id": "3033338e-af6e-442f-80be-d7dea1517e27",
                "title": "NHE Fact Sheet",
                "authors": "None",
                "year": "2025",
                "publication": "CMS.gov",
                "doi": "",
                "summary": "",
                "abstract": "Historical NHE, 2023:\nNHE grew 7.5% to $4.9 trillion in 2023, or $14,570 per person, and accounted for 17.6% of Gross Domestic Product (GDP).\nMedicare spending grew 8.1% to $1,029.8 billion in 2023, or 21 percent of total NHE.\nMedicaid spending grew 7.9% to $871.7 billion in 2023, or 18 percent of total NHE.\nPrivate health insurance spending grew 11.5% to $1,464.6 billion in 2023, or 30 percent of total NHE.\nOut of pocket spending grew 7.2% to $505.7 billion in 2023, or 10 percent of total NHE.\nOther Third Party Payers and Programs and Public Health Activity spending declined 3.1% in 2023 to $563.4 billion, or 12 percent of total NHE.\nHospital expenditures grew 10.4% to $1,519.7 billion in 2023, faster than the 3.2% growth in 2022.\nPhysician and clinical services expenditures grew 7.4% to $978.0 billion in 2023, faster growth than the 4.6% in 2022.\nPrescription drug spending increased 11.4% to $449.7 billion in 2023, faster than the 7.8% growth in 2022.\nThe largest shares of total health spending were sponsored by the federal government (32 percent) and the households (27 percent).   The private business share of health spending accounted for 18 percent of total health care spending, state and local governments accounted for 16 percent, and other private revenues accounted for 7 percent.\nFor further detail see NHE Tables in downloads below.\n\nProjected NHE, 2024-2033:\nOver 2024-33 average NHE growth (5.8 percent) is projected to outpace that of average Gross Domestic Product (GDP) growth (4.3 percent), resulting in an increase in the health spending share of GDP from 17.6 percent in 2023 to 20.3 percent in 2033.\n2024 NHE growth is projected to have been 8.2 percent and to have reflected a continued rebound in the growth of use of services and goods, as well as the high insured share of the population.\nThe insured share of the population in 2024 is projected to have remained high, at 92.1 percent, despite Medicaid enrollment projected to have declined by 7.9 percent (to 84.5 million) following the expiration of the Families First Coronavirus Response Act’s (FFCRA) continuous enrollment provision.\nDirect-purchase enrollment is expected to decline by 4.7 million in 2026 (-12.3 percent) due to the expiration of the Inflation Reduction Act’s (IRA) temporary extension of enhanced subsidies and associated temporary Special Enrollment Period (SEP).\nFor further detail see NHE projections 2024-2033 in downloads below.\n\nNHE by Age Group and Sex, Selected Years 2002, 2004, 2006, 2008, 2010, 2012, 2014, 2016, 2018, and 2020:\nPer person personal health care spending for the 65 and older population was $22,356 in 2020, over 5 times higher than spending per child ($4,217) and almost 2.5 times the spending per working-age person ($9,154).\nIn 2020, children accounted for approximately 23 percent of the population and about 10 percent of all PHC spending.\nThe working-age group comprised the majority of spending and population in 2014, 53 percent and over 60 percent respectively.\nOlder Adults (aged 65 and older) were the smallest population group, about 17 percent of the population, and accounted for approximately 37 percent of all spending in 2020.\nPer person spending for females ($10,887) was 14 percent more than males ($9,554) in 2020.\nIn 2020, per person spending for male children (0-18) was 10 percent more than females.  However, for working age adults per person spending for females was 20 percent more than for males.  For older adults, spending for males was 2 percent more than for females.\nFor further detail see health expenditures by age in downloads below.\n\nNHE by State of Residence, 1991-2020:\nIn 2020, per capita personal health care spending ranged from $7,522 in Utah to $14,007 in New York.   Per capita spending in New York state was 37 percent higher than the national average ($10,191) while spending in Utah was about 26 percent lower.  \nHealth care spending by region continued to exhibit considerable variation. In 2020, the New England and Mideast regions had the highest levels of total per capita personal health care spending ($12,728 and $12,577, respectively), or 25 and 23 percent higher than the national average.   In contrast, the Rocky Mountain and Southwest regions had the lowest levels of total personal health care spending per capita ($8,497 and $8,587, respectively) with average spending 17 and 16 percent lower than the national average, respectively.\nBetween 2014 and 2020, average growth in per capita personal health care spending was highest in New York at 6.1 percent per year and lowest in Wisconsin at 3.0 percent per year (compared with average growth of 4.3 percent nationally).\nThe spread between the highest and the lowest per capita personal health spending across the states has remained relatively stable over 2014-20. Accordingly, the highest per capita spending levels were 90 to 100 percent higher per year than the lowest per capita spending levels during the period.\nMedicare expenditures per beneficiary were highest in Florida ($13,652) and lowest in Vermont ($8,726) in 2020.\nMedicaid expenditures per enrollee were highest in North Dakota ($12,314) and lowest in Georgia ($4,754) in 2020.\nFor further detail, see health expenditures by state of residence in downloads below.\n\nNHE by State of Provider, 1980-2020:\nBetween 2014 and 2020, U.S. personal health care spending grew, on average, 4.8 percent per year, with spending in Arizona growing the fastest (6.6 percent) and spending in Vermont growing the slowest (2.7 percent).\nIn 2020, California’s personal health care spending was highest in the nation ($410.9 billion), representing 12.2 percent of total U.S. personal health care spending. Comparing historical state rankings through 2020, California consistently had the highest level of total personal health care spending, together with the highest total population in the nation. Other large states, New York, Texas, Florida, and Pennsylvania, also were among the states with the highest total personal health care spending.\nWyoming’s personal health care spending was lowest in the nation (as has been the case historically), representing just 0.1 percent of total U.S. personal health care spending in 2020. Vermont, North Dakota, Alaska, and Montana were also among the states with the lowest personal health care spending in both 2020 and historically. All these states have smaller populations.\nGross Domestic Product (GDP) by state measures the value of goods and services produced in each state. Health spending as a share of a state’s GDP shows the importance of the health care sector in a state’s economy. As a share of GDP, West Virginia ranked the highest (28.7 percent) and Washington state the lowest (11.7 percent) in 2020.  ",
                "notes": "",
                "articleType": ""
            },
            {
                "id": "654f0995-ba75-41e6-a586-a9aac7c970d2",
                "title": "Artificial Intelligence–Generated Draft Replies to Patient Inbox Messages",
                "authors": "Garcia Patricia, Ma Stephen P., Shah Shreya, Smith Margaret, Jeong Yejin, Devon-Sand Anna, Tai-Seale Ming, Takazawa Kevin, Clutter Danyelle, Vogt Kyle, Lugtu Carlene, Rojo Matthew, Lin Steven, Shanafelt Tait, Pfeffer Michael A., Sharp Christopher",
                "year": "2024,3,20",
                "publication": "JAMA Network Open",
                "doi": "10.1001/jamanetworkopen.2024.3201",
                "summary": "",
                "abstract": "ImportanceThe emergence and promise of generative artificial intelligence (AI) represent a turning point for health care. Rigorous evaluation of generative AI deployment in clinical practice is needed to inform strategic decision-making.ObjectiveTo evaluate the implementation of a large language model used to draft responses to patient messages in the electronic inbox.Design, Setting, and ParticipantsA 5-week, prospective, single-group quality improvement study was conducted from July 10 through August 13, 2023, at a single academic medical center (Stanford Health Care). All attending physicians, advanced practice practitioners, clinic nurses, and clinical pharmacists from the Divisions of Primary Care and Gastroenterology and Hepatology were enrolled in the pilot.InterventionDraft replies to patient portal messages generated by a Health Insurance Portability and Accountability Act–compliant electronic health record–integrated large language model.Main Outcomes and MeasuresThe primary outcome was AI-generated draft reply utilization as a percentage of total patient message replies. Secondary outcomes included changes in time measures and clinician experience as assessed by survey.ResultsA total of 197 clinicians were enrolled in the pilot; 35 clinicians who were prepilot beta users, out of office, or not tied to a specific ambulatory clinic were excluded, leaving 162 clinicians included in the analysis. The survey analysis cohort consisted of 73 participants (45.1%) who completed both the presurvey and postsurvey. In gastroenterology and hepatology, there were 58 physicians and APPs and 10 nurses. In primary care, there were 83 physicians and APPs, 4 nurses, and 8 clinical pharmacists. The mean AI-generated draft response utilization rate across clinicians was 20%. There was no change in reply action time, write time, or read time between the prepilot and pilot periods. There were statistically significant reductions in the 4-item physician task load score derivative (mean [SD], 61.31 [17.23] presurvey vs 47.26 [17.11] postsurvey; paired difference, −13.87; 95% CI, −17.38 to −9.50; P &amp;amp;lt; .001) and work exhaustion scores (mean [SD], 1.95 [0.79] presurvey vs 1.62 [0.68] postsurvey; paired difference, −0.33; 95% CI, −0.50 to −0.17; P &amp;amp;lt; .001).Conclusions and RelevanceIn this quality improvement study of an early implementation of generative AI, there was notable adoption, usability, and improvement in assessments of burden and burnout. There was no improvement in time. Further code-to-bedside testing is needed to guide future development and organizational strategy.",
                "notes": "",
                "articleType": "journal article"
            },
            {
                "id": "8393832c-fb04-4443-b808-c1b0ddef19be",
                "title": "Testing and Evaluation of Health Care Applications of Large Language Models",
                "authors": "Bedi Suhana, Liu Yutong, Orr-Ewing Lucy, Dash Dev, Koyejo Sanmi, Callahan Alison, Fries Jason A., Wornow Michael, Swaminathan Akshay, Lehmann Lisa Soleymani, Hong Hyo Jung, Kashyap Mehr, Chaurasia Akash R., Shah Nirav R., Singh Karandeep, Tazbaz Troy, Milstein Arnold, Pfeffer Michael A., Shah Nigam H.",
                "year": "2025,1,28",
                "publication": "JAMA",
                "doi": "10.1001/jama.2024.21700",
                "summary": "",
                "abstract": "ImportanceLarge language models (LLMs) can assist in various health care activities, but current evaluation approaches may not adequately identify the most useful application areas.ObjectiveTo summarize existing evaluations of LLMs in health care in terms of 5 components: (1) evaluation data type, (2) health care task, (3) natural language processing (NLP) and natural language understanding (NLU) tasks, (4) dimension of evaluation, and (5) medical specialty.Data SourcesA systematic search of PubMed and Web of Science was performed for studies published between January 1, 2022, and February 19, 2024.Study SelectionStudies evaluating 1 or more LLMs in health care.Data Extraction and SynthesisThree independent reviewers categorized studies via keyword searches based on the data used, the health care tasks, the NLP and NLU tasks, the dimensions of evaluation, and the medical specialty.ResultsOf 519 studies reviewed, published between January 1, 2022, and February 19, 2024, only 5% used real patient care data for LLM evaluation. The most common health care tasks were assessing medical knowledge such as answering medical licensing examination questions (44.5%) and making diagnoses (19.5%). Administrative tasks such as assigning billing codes (0.2%) and writing prescriptions (0.2%) were less studied. For NLP and NLU tasks, most studies focused on question answering (84.2%), while tasks such as summarization (8.9%) and conversational dialogue (3.3%) were infrequent. Almost all studies (95.4%) used accuracy as the primary dimension of evaluation; fairness, bias, and toxicity (15.8%), deployment considerations (4.6%), and calibration and uncertainty (1.2%) were infrequently measured. Finally, in terms of medical specialty area, most studies were in generic health care applications (25.6%), internal medicine (16.4%), surgery (11.4%), and ophthalmology (6.9%), with nuclear medicine (0.6%), physical medicine (0.4%), and medical genetics (0.2%) being the least represented.Conclusions and RelevanceExisting evaluations of LLMs mostly focus on accuracy of question answering for medical examinations, without consideration of real patient care data. Dimensions such as fairness, bias, and toxicity and deployment considerations received limited attention. Future evaluations should adopt standardized applications and metrics, use clinical data, and broaden focus to include a wider range of tasks and specialties.",
                "notes": "",
                "articleType": "journal article"
            },
            {
                "id": "ab745c64-ed2e-45a8-8443-68769cb556cc",
                "title": "AI, Health, and Health Care Today and Tomorrow",
                "authors": "Angus Derek C., Khera Rohan, Lieu Tracy, Liu Vincent, Ahmad Faraz S., Anderson Brian, Bhavani Sivasubramanium V., Bindman Andrew, Brennan Troyen, Celi Leo Anthony, Chen Frederick, Cohen I. Glenn, Denniston Alastair, Desai Sanjay, Embí Peter, Faisal Aldo, Ferryman Kadija, Gerhart Jackie, Gross Marielle, Hernandez-Boussard Tina, Howell Michael, Johnson Kevin, Lee Kristine, Liu Xiaoxuan, Lomis Kimberly, London Alex John, Longhurst Christopher A., Mandl Kenneth D., McGlynn Elizabeth, Mello Michelle M., Munoz Fatima, Ohno-Machado Lucila, Ouyang David, Perlis Roy, Phillips Adam, Rhew David, Ross Joseph S., Saria Suchi, Schwamm Lee, Seymour Christopher W., Shah Nigam H., Shah Rashmee, Singh Karandeep, Solomon Matthew, Spates Kathryn, Spector-Bagdady Kayte, Wang Tommy, Gichoya Judy Wawira, Weinstein James, Wiens Jenna, Bibbins-Domingo Kirsten, undefined , Alterovitz Gil, Clancy Heather A, Dawson Lindsay, Diamond Matthew, Holve Erin C, Kahn Jeremy, Pengetnze Yolande M, Rao Shiv, Shrank William H, Termulo Cesar",
                "year": "2025,11,11",
                "publication": "JAMA",
                "doi": "10.1001/jama.2025.18490",
                "summary": "",
                "abstract": "\n                    Importance\n                    Artificial intelligence (AI) is changing health and health care on an unprecedented scale. Though the potential benefits are massive, so are the risks. The JAMA Summit on AI discussed how health and health care AI should be developed, evaluated, regulated, disseminated, and monitored.\n                  \n                  \n                    Observations\n                    Health and health care AI is wide-ranging, including clinical tools (eg, sepsis alerts or diabetic retinopathy screening software), technologies used by individuals with health concerns (eg, mobile health apps), tools used by health care systems to improve business operations (eg, revenue cycle management or scheduling), and hybrid tools supporting both business operations (eg, documentation and billing) and clinical activities (eg, suggesting diagnoses or treatment plans). Many AI tools are already widely adopted, especially for medical imaging, mobile health, health care business operations, and hybrid functions like scribing outpatient visits. All these tools can have important health effects (good or bad), but these effects are often not quantified because evaluations are extremely challenging or not required, in part because many are outside the US Food and Drug Administration’s regulatory oversight. A major challenge in evaluation is that a tool’s effects are highly dependent on the human-computer interface, user training, and setting in which the tool is used. Numerous efforts lay out standards for the responsible use of AI, but most focus on monitoring for safety (eg, detection of model hallucinations) or institutional compliance with various process measures, and do not address effectiveness (ie, demonstration of improved outcomes). Ensuring AI is deployed equitably and in a manner that improves health outcomes or, if improving efficiency of health care delivery, does so safely, requires progress in 4 areas. First, multistakeholder engagement throughout the total product life cycle is needed. This effort would include greater partnership of end users with developers in initial tool creation and greater partnership of developers, regulators, and health care systems in the evaluation of tools as they are deployed. Second, measurement tools for evaluation and monitoring should be developed and disseminated. Beyond proposed monitoring and certification initiatives, this will require new methods and expertise to allow health care systems to conduct or participate in rapid, efficient, and robust evaluations of effectiveness. The third priority is creation of a nationally representative data infrastructure and learning environment to support the generation of generalizable knowledge about health effects of AI tools across different settings. Fourth, an incentive structure should be promoted, using market forces and policy levers, to drive these changes.\n                  \n                  \n                    Conclusions and Relevance\n                    AI will disrupt every part of health and health care delivery in the coming years. Given the many long-standing problems in health care, this disruption represents an incredible opportunity. However, the odds that this disruption will improve health for all will depend heavily on the creation of an ecosystem capable of rapid, efficient, robust, and generalizable knowledge about the consequences of these tools on health.\n                  ",
                "notes": "",
                "articleType": "journal article"
            },
            {
                "id": "1bf92709-0a24-4444-847c-6e016426b435",
                "title": "Testing and Evaluation of Health Care Applications of Large Language Models",
                "authors": "Bedi Suhana, Liu Yutong, Orr-Ewing Lucy, Dash Dev, Koyejo Sanmi, Callahan Alison, Fries Jason A., Wornow Michael, Swaminathan Akshay, Lehmann Lisa Soleymani, Hong Hyo Jung, Kashyap Mehr, Chaurasia Akash R., Shah Nirav R., Singh Karandeep, Tazbaz Troy, Milstein Arnold, Pfeffer Michael A., Shah Nigam H.",
                "year": "2025,1,28",
                "publication": "JAMA",
                "doi": "10.1001/jama.2024.21700",
                "summary": "",
                "abstract": "ImportanceLarge language models (LLMs) can assist in various health care activities, but current evaluation approaches may not adequately identify the most useful application areas.ObjectiveTo summarize existing evaluations of LLMs in health care in terms of 5 components: (1) evaluation data type, (2) health care task, (3) natural language processing (NLP) and natural language understanding (NLU) tasks, (4) dimension of evaluation, and (5) medical specialty.Data SourcesA systematic search of PubMed and Web of Science was performed for studies published between January 1, 2022, and February 19, 2024.Study SelectionStudies evaluating 1 or more LLMs in health care.Data Extraction and SynthesisThree independent reviewers categorized studies via keyword searches based on the data used, the health care tasks, the NLP and NLU tasks, the dimensions of evaluation, and the medical specialty.ResultsOf 519 studies reviewed, published between January 1, 2022, and February 19, 2024, only 5% used real patient care data for LLM evaluation. The most common health care tasks were assessing medical knowledge such as answering medical licensing examination questions (44.5%) and making diagnoses (19.5%). Administrative tasks such as assigning billing codes (0.2%) and writing prescriptions (0.2%) were less studied. For NLP and NLU tasks, most studies focused on question answering (84.2%), while tasks such as summarization (8.9%) and conversational dialogue (3.3%) were infrequent. Almost all studies (95.4%) used accuracy as the primary dimension of evaluation; fairness, bias, and toxicity (15.8%), deployment considerations (4.6%), and calibration and uncertainty (1.2%) were infrequently measured. Finally, in terms of medical specialty area, most studies were in generic health care applications (25.6%), internal medicine (16.4%), surgery (11.4%), and ophthalmology (6.9%), with nuclear medicine (0.6%), physical medicine (0.4%), and medical genetics (0.2%) being the least represented.Conclusions and RelevanceExisting evaluations of LLMs mostly focus on accuracy of question answering for medical examinations, without consideration of real patient care data. Dimensions such as fairness, bias, and toxicity and deployment considerations received limited attention. Future evaluations should adopt standardized applications and metrics, use clinical data, and broaden focus to include a wider range of tasks and specialties.",
                "notes": "",
                "articleType": "journal article"
            },
            {
                "id": "a5274514-da89-4708-91f1-72b990cb52d2",
                "title": "Large language models encode clinical knowledge.",
                "authors": "Singhal Karan, Azizi Shekoofeh, Tu Tao, Mahdavi S Sara, Wei Jason, Chung Hyung Won, Scales Nathan, Tanwani Ajay, Cole-Lewis Heather, Pfohl Stephen, Payne Perry, Seneviratne Martin, Gamble Paul, Kelly Chris, Babiker Abubakr, Schärli Nathanael, Chowdhery Aakanksha, Mansfield Philip, Demner-Fushman Dina, Agüera Y Arcas Blaise, Webster Dale, Corrado Greg S, Matias Yossi, Chou Katherine, Gottweis Juraj, Tomasev Nenad, Liu Yun, Rajkomar Alvin, Barral Joelle, Semturs Christopher, Karthikesalingam Alan, Natarajan Vivek",
                "year": "2023",
                "publication": "Nature",
                "doi": "10.1038/s41586-023-06291-2",
                "summary": "",
                "abstract": "Large language models (LLMs) have demonstrated impressive capabilities, but the bar for clinical applications is high. Attempts to assess the clinical knowledge of models typically rely on automated evaluations based on limited benchmarks. Here, to address these limitations, we present MultiMedQA, a benchmark combining six existing medical question answering datasets spanning professional medicine, research and consumer queries and a new dataset of medical questions searched online, HealthSearchQA. We propose a human evaluation framework for model answers along multiple axes including factuality, comprehension, reasoning, possible harm and bias. In addition, we evaluate Pathways Language Model1 (PaLM, a 540-billion parameter LLM) and its instruction-tuned variant, Flan-PaLM2 on MultiMedQA. Using a combination of prompting strategies, Flan-PaLM achieves state-of-the-art accuracy on every MultiMedQA multiple-choice dataset (MedQA3, MedMCQA4, PubMedQA5 and Measuring Massive Multitask Language Understanding (MMLU) clinical topics6), including 67.6% accuracy on MedQA (US Medical Licensing Exam-style questions), surpassing the prior state of the art by more than 17%. However, human evaluation reveals key gaps. To resolve this, we introduce instruction prompt tuning, a parameter-efficient approach for aligning LLMs to new domains using a few exemplars. The resulting model, Med-PaLM, performs encouragingly, but remains inferior to clinicians. We show that comprehension, knowledge recall and reasoning improve with model scale and instruction prompt tuning, suggesting the potential utility of LLMs in medicine. Our human evaluations reveal limitations of today's models, reinforcing the importance of both evaluation frameworks and method development in creating safe, helpful LLMs for clinical applications.",
                "notes": "",
                "articleType": "Comparative Study, Research Support, Non-U.S. Gov't"
            },
            {
                "id": "84f2e81c-88b2-4394-8468-9412e0aef12a",
                "title": "Automatic Prompt Optimization with \"Gradient Descent\" and Beam Search",
                "authors": "Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang Zhu, Michael Zeng",
                "year": "2025",
                "publication": "arXiv",
                "doi": "10.48550/arXiv.2305.03495",
                "summary": "",
                "abstract": "Large Language Models (LLMs) have shown impressive performance as general purpose agents, but their abilities remain highly dependent on prompts which are hand written with onerous trial-and-error effort. We propose a simple and nonparametric solution to this problem, Automatic Prompt Optimization (APO), which is inspired by numerical gradient descent to automatically improve prompts, assuming access to training data and an LLM API. The algorithm uses minibatches of data to form natural language \"gradients\" that criticize the current prompt. The gradients are then \"propagated\" into the prompt by editing the prompt in the opposite semantic direction of the gradient. These gradient descent steps are guided by a beam search and bandit selection procedure which significantly improves algorithmic efficiency. Preliminary results across three benchmark NLP tasks and the novel problem of LLM jailbreak detection suggest that Automatic Prompt Optimization can outperform prior prompt editing techniques and improve an initial prompt's performance by up to 31%, by using data to rewrite vague task descriptions into more precise annotation instructions.",
                "notes": "",
                "articleType": ""
            }
        ],
        "figures": []
    }
]